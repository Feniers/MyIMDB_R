{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from annoy import AnnoyIndex\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 使用 low_memory=False 选项读取文件\n",
    "ratings = pd.read_csv('ratings_small.csv', encoding='latin1')\n",
    "movies_metadata = pd.read_csv('movies_metadata.csv', encoding='latin1', low_memory=False)\n",
    "\n",
    "\n",
    "# 创建用户-物品矩阵\n",
    "user_item_matrix = ratings.pivot(index='userId', columns='movieId', values='rating')\n",
    "\n",
    "# 计算物品相似度\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "item_similarity = cosine_similarity(user_item_matrix.fillna(0).T)\n",
    "item_similarity_df = pd.DataFrame(item_similarity, index=user_item_matrix.columns, columns=user_item_matrix.columns)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-28T14:01:07.702570300Z",
     "start_time": "2024-05-28T14:01:05.478384Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for user 1: [1387, 1266, 1214, 3108, 2194]\n"
     ]
    }
   ],
   "source": [
    "def item_based_recommendations(user_id, user_item_matrix, item_similarity_df, num_recommendations=5):\n",
    "    user_ratings = user_item_matrix.loc[user_id].dropna()\n",
    "    similar_items = pd.Series(dtype=float)\n",
    "\n",
    "    for i, rating in user_ratings.items():\n",
    "        similars = item_similarity_df[i].drop(user_ratings.index)\n",
    "        similar_items = pd.concat([similar_items, similars])\n",
    "\n",
    "    similar_items = similar_items.groupby(similar_items.index).sum()\n",
    "    similar_items.sort_values(inplace=True, ascending=False)\n",
    "\n",
    "    recommendations = similar_items.head(num_recommendations).index.tolist()\n",
    "    return recommendations\n",
    "\n",
    "\n",
    "# 为用户1生成推荐\n",
    "user_id = 1\n",
    "recommendations = item_based_recommendations(user_id, user_item_matrix, item_similarity_df)\n",
    "print(f\"Recommendations for user {user_id}: {recommendations}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-28T14:01:07.775570200Z",
     "start_time": "2024-05-28T14:01:07.703568Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# 基于内容的推荐函数\n",
    "# 处理文本数据\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "movies_metadata['description'] = movies_metadata['overview'].fillna('')\n",
    "tfidf_matrix = tfidf.fit_transform(movies_metadata['description'])\n",
    "\n",
    "# 使用 Annoy 构建近似最近邻索引\n",
    "f = tfidf_matrix.shape[1]\n",
    "annoy_index = AnnoyIndex(f, 'angular')\n",
    "\n",
    "for i in range(tfidf_matrix.shape[0]):\n",
    "    annoy_index.add_item(i, tfidf_matrix[i].toarray()[0])\n",
    "\n",
    "annoy_index.build(10)  # 10 棵树\n",
    "\n",
    "def content_based_recommendations(movie_id, annoy_index, movies_metadata, num_recommendations=5):\n",
    "    movie_id = str(movie_id)\n",
    "\n",
    "    if movie_id not in movies_metadata['id'].values:\n",
    "        print(f\"Movie ID {movie_id} not found in metadata\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    idx = movies_metadata[movies_metadata['id'] == movie_id].index[0]\n",
    "    sim_scores = annoy_index.get_nns_by_item(idx, num_recommendations + 1)[1:]\n",
    "    return movies_metadata.iloc[sim_scores]\n",
    "\n",
    "# 为电影生成推荐\n",
    "movie_id = 1\n",
    "recommendations = content_based_recommendations(movie_id, annoy_index, movies_metadata)\n",
    "if not recommendations.empty:\n",
    "    print(f\"Recommendations for movie {movie_id}: {recommendations[['title', 'id']]}\")\n",
    "else:\n",
    "    print(f\"No recommendations available for movie ID {movie_id}\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-05-28T14:01:07.778572200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 混合推荐函数\n",
    "def hybrid_recommendations(user_id, movie_id, user_item_matrix, item_similarity_df, annoy_index, movies_metadata, cf_weight=0.5, cb_weight=0.5):\n",
    "    cf_recs = item_based_recommendations(user_id, user_item_matrix, item_similarity_df, num_recommendations=10)\n",
    "    cb_recs = content_based_recommendations(movie_id, annoy_index, movies_metadata, num_recommendations=10)\n",
    "\n",
    "    if cb_recs.empty:\n",
    "        return cf_recs[:5]\n",
    "\n",
    "    cf_recs_df = pd.DataFrame({'movieId': cf_recs, 'score': [cf_weight] * len(cf_recs)})\n",
    "    cb_recs_df = pd.DataFrame({'movieId': cb_recs['id'], 'score': [cb_weight] * len(cb_recs)})\n",
    "\n",
    "    hybrid_recs = pd.concat([cf_recs_df, cb_recs_df]).groupby('movieId').sum().sort_values(by='score', ascending=False)\n",
    "    return hybrid_recs.head(5).index.tolist()\n",
    "\n",
    "# 为用户和电影生成混合推荐\n",
    "user_id = 1\n",
    "movie_id = 1\n",
    "hybrid_recs = hybrid_recommendations(user_id, movie_id, user_item_matrix, item_similarity_df, annoy_index, movies_metadata)\n",
    "print(f\"Hybrid Recommendations for user {user_id}: {hybrid_recs}\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userId  movieId  rating\n",
      "0       0        0     2.5\n",
      "1       0        1     3.0\n",
      "2       0        2     3.0\n",
      "3       0        3     2.0\n",
      "4       0        4     4.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# 加载数据\n",
    "ratings = pd.read_csv('ratings_small.csv')\n",
    "movies_metadata = pd.read_csv('movies_metadata.csv', encoding='latin1', low_memory=False)\n",
    "\n",
    "# 数据预处理\n",
    "# 过滤出合法的 movieId 和 userId\n",
    "ratings = ratings[['userId', 'movieId', 'rating']]\n",
    "\n",
    "# 创建 userId 和 movieId 的映射\n",
    "user_id_mapping = {id: i for i, id in enumerate(ratings['userId'].unique())}\n",
    "movie_id_mapping = {id: i for i, id in enumerate(ratings['movieId'].unique())}\n",
    "\n",
    "# 映射到新的索引\n",
    "ratings['userId'] = ratings['userId'].map(user_id_mapping)\n",
    "ratings['movieId'] = ratings['movieId'].map(movie_id_mapping)\n",
    "\n",
    "# 转换为张量\n",
    "ratings_tensor = torch.tensor(ratings.values, dtype=torch.float32)\n",
    "\n",
    "# 训练集和测试集划分\n",
    "train_tensor, test_tensor = train_test_split(ratings_tensor, test_size=0.2, random_state=42)\n",
    "\n",
    "# 检查数据\n",
    "print(ratings.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-28T15:20:13.579831400Z",
     "start_time": "2024-05-28T15:20:12.667385700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# 定义数据集类\n",
    "class RatingsDataset(Dataset):\n",
    "    def __init__(self, ratings):\n",
    "        self.ratings = ratings\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ratings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.ratings[idx, :3]\n",
    "\n",
    "train_dataset = RatingsDataset(train_tensor)\n",
    "test_dataset = RatingsDataset(test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-28T15:20:29.903685600Z",
     "start_time": "2024-05-28T15:20:29.882416600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MatrixFactorization(\n",
      "  (user_embedding): Embedding(671, 50)\n",
      "  (item_embedding): Embedding(9066, 50)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 定义模型\n",
    "class MatrixFactorization(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim=20):\n",
    "        super(MatrixFactorization, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_dim)\n",
    "\n",
    "    def forward(self, user, item):\n",
    "        user_embedded = self.user_embedding(user)\n",
    "        item_embedded = self.item_embedding(item)\n",
    "        return (user_embedded * item_embedded).sum(1)\n",
    "\n",
    "# 获取用户和物品的数量\n",
    "num_users = ratings['userId'].nunique()\n",
    "num_items = ratings['movieId'].nunique()\n",
    "\n",
    "# 初始化模型\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = MatrixFactorization(num_users, num_items, embedding_dim=50).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "print(model)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-28T15:20:32.505619500Z",
     "start_time": "2024-05-28T15:20:32.481372Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 39.83473800564651\n",
      "Epoch 2/20, Loss: 8.069735024853957\n",
      "Epoch 3/20, Loss: 2.413070353672659\n",
      "Epoch 4/20, Loss: 1.7365394844401845\n",
      "Epoch 5/20, Loss: 2.1562769540208135\n",
      "Epoch 6/20, Loss: 2.2979685268956693\n",
      "Epoch 7/20, Loss: 1.7757424617842805\n",
      "Epoch 8/20, Loss: 1.4013934999251727\n",
      "Epoch 9/20, Loss: 1.2803011572213292\n",
      "Epoch 10/20, Loss: 1.260276926411904\n",
      "Epoch 11/20, Loss: 1.1655608230738712\n",
      "Epoch 12/20, Loss: 1.0828681909304252\n",
      "Epoch 13/20, Loss: 1.0190056783022832\n",
      "Epoch 14/20, Loss: 0.9833268187076544\n",
      "Epoch 15/20, Loss: 0.9526256298561462\n",
      "Epoch 16/20, Loss: 0.9233448592831286\n",
      "Epoch 17/20, Loss: 0.8937154515958328\n",
      "Epoch 18/20, Loss: 0.8769234113698955\n",
      "Epoch 19/20, Loss: 0.8646028796784121\n",
      "Epoch 20/20, Loss: 0.8457783781510178\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        users = batch[:, 0].long().to(device)\n",
    "        items = batch[:, 1].long().to(device)\n",
    "        ratings = batch[:, 2].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(users, items)\n",
    "        loss = criterion(outputs, ratings)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_loader)}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-28T15:23:11.759900600Z",
     "start_time": "2024-05-28T15:20:56.677562Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              title     id\n",
      "5755                 Making Contact   7011\n",
      "6655            The Meaning of Life   4543\n",
      "8728              The Holy Mountain   8327\n",
      "8452   Letter from an Unknown Woman    946\n",
      "34393                   Kurukshetra  81782\n",
      "16221                  Doppelganger  32234\n",
      "6282        Man with a Movie Camera  26317\n",
      "28180                At Point Blank   8743\n",
      "11148      The Secret Life of Words    148\n",
      "7235           Mother, Jugs & Speed  26176\n"
     ]
    }
   ],
   "source": [
    "def recommend_movies(user_id, model, movies_metadata, user_id_mapping, movie_id_mapping, top_n=10):\n",
    "    model.eval()\n",
    "\n",
    "    # 将用户 ID 转换为张量\n",
    "    user_id_tensor = torch.tensor([user_id_mapping[user_id]]).long().to(device)\n",
    "    # 创建一个包含所有电影 ID 的张量\n",
    "    item_ids = torch.arange(num_items).long().to(device)\n",
    "\n",
    "    # 使用模型进行预测\n",
    "    with torch.no_grad():\n",
    "        predictions = model(user_id_tensor.repeat(num_items), item_ids)\n",
    "\n",
    "    # 对预测结果进行排序\n",
    "    _, indices = torch.sort(predictions, descending=True)\n",
    "    recommended_movie_ids = [item_ids[idx].item() for idx in indices]\n",
    "\n",
    "    # 将推荐的电影 ID 转换为原始 ID\n",
    "    original_movie_ids = {v: k for k, v in movie_id_mapping.items()}\n",
    "    recommended_original_ids = [original_movie_ids[mid] for mid in recommended_movie_ids]\n",
    "\n",
    "    # 获取存在于 movies_metadata 中的电影 ID\n",
    "    valid_movie_ids = set(movies_metadata['id'].astype(str).unique())\n",
    "\n",
    "    # 过滤掉不存在的电影 ID\n",
    "    recommended_original_ids = [mid for mid in recommended_original_ids if str(mid) in valid_movie_ids]\n",
    "\n",
    "    # 获取推荐的电影\n",
    "    recommended_movies = []\n",
    "    for mid in recommended_original_ids:\n",
    "        if len(recommended_movies) == top_n:\n",
    "            break\n",
    "        recommended_movie = movies_metadata[movies_metadata['id'].astype(str) == str(mid)]\n",
    "        if not recommended_movie.empty:\n",
    "            recommended_movies.append(recommended_movie)\n",
    "\n",
    "    return pd.concat(recommended_movies)\n",
    "\n",
    "# 假设你要为用户ID 1推荐\n",
    "user_id = 3\n",
    "recommended_movies = recommend_movies(user_id, model, movies_metadata, user_id_mapping, movie_id_mapping)\n",
    "print(recommended_movies[['title', 'id']])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-28T15:28:16.197644700Z",
     "start_time": "2024-05-28T15:28:16.063224700Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
